{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f782f2e7-d253-4390-aff9-851a424803e1",
   "metadata": {},
   "source": [
    "# Preparations at home"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7413cd4b-31d5-45ef-89bd-c2d4e782dbc5",
   "metadata": {},
   "source": [
    "## Installation of the package\n",
    "\n",
    " 1. (Only needed on Windows) Install the Windows Subsystem for Linux following [these instructions](https://learn.microsoft.com/en-us/windows/wsl/setup/environment). Then execute the following steps (including for starting the notebook) within a wsl environent. You can start one by typing `wsl` in a Powershell.\n",
    " 2. To install a micromamba instance (if no mamba/conda is available) with all the dependencies in a dedicated environment, there is a bash script available. Take a look at the script at the script at the location that is downloaded *via* `wget` and confirm it is safe. Then download and execute the installation script by executing:\n",
    "\n",
    "    ```bash    \n",
    "        wget https://github.com/Niolon/XHARPy/raw/refs/heads/main/install.sh \n",
    "        bash install.sh\n",
    "        \n",
    "    ```\n",
    "    Do **not** execute via `sudo`, doing that potentially makes your conda environments unusable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fbff4b-a349-4e0c-bc21-ccc314a91db7",
   "metadata": {},
   "source": [
    "## Starting the notebook \n",
    "You can start the notebook by opening a command line / shell in the folder where you have executed the command above (on windows use the WSL shell). Then type\n",
    "\n",
    "```bash\n",
    "conda activate xharpy\n",
    "jupyter lab\n",
    "```\n",
    "After a short while a new website should open up. If if does not, open the link in the console output. Within the Jupyter UI, navigate to `Examples/Workshop_Erice` and open the `Workshop.ipynb` You should see an identical copy to these lecture notes as an interactive Jupyter notebook.\n",
    "\n",
    "## Test the installation\n",
    "Within the interactive version, you can execute the following cells by clicking on the cell and pressing `Shift + Enter`. If all of the tests show a pass: Congratulations you are ready for the workshop and have a running version of XHARPy on your computer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123bcc45-d5ae-4435-9c10-abb7a4e2b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workshop_tests import test_xharpy_installation\n",
    "test_xharpy_installation();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d37f163-ed41-4899-a57e-1101e5d9f712",
   "metadata": {},
   "source": [
    "# Introduction: What does XHARPy do?\n",
    "\n",
    " - Hirshfeld Atom Refinement (with partitioned valence densities)\n",
    " - atomic form factor calculation\n",
    " - Doing these things with periodic densities evaluated on rectangular grids with separately evaluated frozen core densities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8f80a7-196c-437d-b171-9824c5664102",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bb2e4c-a6e5-49b6-9e88-ecbe2f7774ca",
   "metadata": {},
   "source": [
    "## The two minute introduction to python programming\n",
    "\n",
    "As you might imagine this is not a python course, just a short glossary of the syntax that will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a4c05c-dc28-48b3-9eb0-63c151b6c876",
   "metadata": {},
   "source": [
    "Values from the right are assigned to a variable on the left with the `=` operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee62ae97-0e4f-4c5d-81c1-27aef5a59f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dee768-e450-4d0c-8dcb-38946580aaa4",
   "metadata": {},
   "source": [
    "To save text we need to start and end with the same type of quotation mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e94d7a-e8d1-4991-9ca7-ba920292bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_string = \"String content\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bfd76c-f02c-459e-a841-a5c4bcffd79f",
   "metadata": {},
   "source": [
    "A dictionary is started and ended with curly braces and pairs of key: values separated by a colon. They are used for settings in this tutorial if you know how to write JSON you can basically transfer what you know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e25f26-f7a1-47d0-a320-3346c0382efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\"setting_name\": 1, \"another_setting_name\": \"another value\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5776dd2-06ce-4393-ba3b-877f0b8104de",
   "metadata": {},
   "source": [
    "we access / assign / modify a value in a dict using square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb060d-5d98-4045-a8f2-e96c8f4fe851",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = my_dict[\"setting_name\"]\n",
    "my_dict[\"a_third_setting\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac32de08-232a-4e41-a341-7272450caa31",
   "metadata": {},
   "source": [
    "A function has a name and round brackets, in which you input arguments by position and/or by name. It can produce one or more *return values* that can be assigned to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f70d29-f23b-4f48-8f15-b4d73200da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Output\")  # no return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e870e-20ff-449c-b764-5e277638476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dict(name=\"Alice\", age=30, city=\"New York\")\n",
    "print(result)  # we can use variables as arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aec6d4-f346-4a12-8eaa-e87ea73da428",
   "metadata": {},
   "source": [
    "We get more functionality / functions by importing them from installed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7269f61-54f7-47c7-af73-8d0b82a612c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e3e43-8b92-4f18-bd71-47b60801265c",
   "metadata": {},
   "source": [
    "# Using XHARPy\n",
    "First we will import the functions needed to road the data, execute the refinement and write the results back to disk. At the first time you import something you should get a warning about JAX using the CPU. This is expected (otherwise you need a 64 bit capable GPU, and refinement on the GPU is untested)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a3066-de95-40c3-b325-7e5a4e6ea84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions for reading the intensities\n",
    "from xharpy import shelxl_hkl2pd  # For a SHELX HKL 4 (that needs to be merged!)\n",
    "from xharpy import xd_hkl2pd  # For a XD hkl containing intensities\n",
    "from xharpy import fcf2hkl_pd # For reading the observed intensities from an fcf4 (do not correct the extinction against the IAM).\n",
    "\n",
    "# import function to read other data\n",
    "from xharpy import cif2data, lst2constraint_dict\n",
    "\n",
    "# import functions needed for refinement\n",
    "from xharpy import create_construction_instructions, refine\n",
    "\n",
    "# import function to write out the results\n",
    "from xharpy import write_cif, write_res, write_fcf, add_density_entries_from_fcf\n",
    "\n",
    "# import functions to create a tsc file\n",
    "from xharpy import cif2tsc\n",
    "\n",
    "# Path is a really convenient way to work with pathes in python. (should already be present from example above)\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea82923f-b8dd-44a0-bd5a-e7c6686e1ab7",
   "metadata": {},
   "source": [
    "All functions within XHARPy should have a working in-function documentation (so a docstring), which you can access via python's help function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a6ec94-af4b-4033-a56b-5ffcf274de21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(refine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c807e2-fbe7-4e79-bf4a-308d666e9d5a",
   "metadata": {},
   "source": [
    "## Refining with Quantum Espresso: CaF<sub>2</sub>\n",
    "Note that there is no logic between the assignment of calculation program for the density used in this tutorial: The aim is two show the two backend-engines and two different structures.\n",
    "\n",
    "Let us start to work on the first dataset by creating references to the folders needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9c280f-e23d-4e44-ba1a-fea0a596d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_caf2 = Path(\"CaF2\")\n",
    "output_folder_caf2 = folder_caf2 / \"xharpy_output\"\n",
    "output_folder_caf2.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d660e1-a8b5-477b-aaa2-5636913c216b",
   "metadata": {},
   "source": [
    "### Loading the data and merging the hkl\n",
    "There is a lot of different objects that will be created from the cif file using the `cif2data` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ffb469-198b-4697-a10c-75214d437ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_table_caf2, cell_caf2, cell_esd_caf2, symm_mats_vecs_caf2, symm_strings_caf2, wavelength_caf2 = cif2data(folder_caf2 / \"CaF2.cif\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0524be8a-2d53-40ca-b3a3-1b659eae5a71",
   "metadata": {},
   "source": [
    "First it is instructive to take a quick look at the imported `atom_table_caf2`. This an object which has a nice representation in the Jupyter notebook (for reference: it is a pandas DataFrame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b624d56a-8f3d-47c7-8efa-893ca800898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_table_caf2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed5e5a8-338c-4e27-bcdb-5c355ce5d26e",
   "metadata": {},
   "source": [
    "We can load and merge the hkl, check that the space group is correct. XHARPy will execute with unmerged reflections. However the refinement will get slow and the result will not be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c58ea-ebd4-4b46-8537-59efee9f0c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "hkl_caf2 = fcf2hkl_pd(folder_caf2/  'CaF2.fcf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38567b1f-7243-4073-bf07-657ae6c8d3db",
   "metadata": {},
   "source": [
    "The final file, we need is an SHELXL lst file for the special position constraints. These can also be generated manually (as described [here](https://xharpy.readthedocs.io/en/latest/library/library_symm_con.html)). However creating them from an lst is more convenient. For reference, this is what this function is looking for. It might be possible to recreate this without ShelXl (make sure to create the spaces around the `*` signs): \n",
    "```\n",
    " Special position constraints for Ca01\n",
    " x =  0.5000   y =  0.5000   z =  0.5000   U22 = 1.0 * U11   U33 = 1.0 * U11   \n",
    " U23 = 0   U13 = 0   U12 = 0   sof = 0.02083   \n",
    " Input constraints retained (at least in part) for  sof\n",
    "\n",
    " Special position constraints for F002\n",
    " x =  0.2500   y =  0.7500   z =  0.7500   U22 = 1.0 * U11   U33 = 1.0 * U11   \n",
    " U23 = 0   U13 = 0   U12 = 0   sof = 0.04167   \n",
    " Input constraints retained (at least in part) for  sof\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a1c7ea-ec94-48de-a809-29f52529cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_caf2 = lst2constraint_dict(folder_caf2 / 'CaF2.lst')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3907e66-c451-424c-b58f-da4da8d08617",
   "metadata": {},
   "source": [
    "### Setting up the refinement\n",
    "The `refinement_dict` is used to control the refinement on a macroscopic scale. Available options can be found in the docstring of `refine` or in the [online documentation](https://xharpy.readthedocs.io/en/latest/library/library_refinement_dict.html). \n",
    "\n",
    "Settings that can be changed:\n",
    "  - `f0j_source`:\n",
    "    \n",
    "    Source of the atomic form factors. The computation_dict \n",
    "    will be passed on to this method. See the individual files in\n",
    "    f0j_sources for more information, by default `'gpaw'`\n",
    "    Tested options: `'gpaw'`, `'iam'`, `'gpaw_mpi'`, `'qe'`, `'tsc_file'`\n",
    "    Experimental options: `'nosphera2_orca'`, `'custom_function'`\n",
    "    \n",
    "  - `reload_step`:\n",
    "    \n",
    "    Starting with this step the computation will try to reuse the \n",
    "    density, if this is implemented in the source, by default 1\n",
    "    \n",
    "  - `core`:\n",
    "    \n",
    "    If this is implemented in a f0j_source, it will integrate the \n",
    "    frozen core density on a spherical grid and only use the valence\n",
    "    density for the updated atomic form factos options are \n",
    "    'combine', which will not treat the core density separately,\n",
    "    'constant' which will integrate and add the core density without\n",
    "    scaling parameter and 'scale' which will refine a scaling \n",
    "    parameter for the core density which might for systematic\n",
    "    deviations due to a coarse valence density grid (untested!)\n",
    "    By default 'constant'\n",
    "    \n",
    "  - `extinction`:\n",
    "    \n",
    "    Use an extinction correction. Options: 'none' -> no extinction\n",
    "    correction, 'shelxl' use the (empirical) formula used by SHELXL \n",
    "    to correct to correct for extinction, 'secondary' see Giacovazzo\n",
    "    et al. 'Fundmentals of Crystallography' (1992) p.97, by default\n",
    "    'none'\n",
    "\n",
    "  - `max_dist_recalc`:\n",
    "\n",
    "    If the max difference in atomic positions is under this value in \n",
    "    Angstroems, no new structure factors will be calculated, by\n",
    "    default 1e-6\n",
    "\n",
    "  - `max_iter`:\n",
    "\n",
    "    Maximum of refinement cycles if convergence not reached, by \n",
    "    default: 100\n",
    "\n",
    "  - `min_iter`:\n",
    "\n",
    "    Minimum refinement cycles. The refinement will stop if the\n",
    "    wR2 increases if the current cycle is higher than min_iter,\n",
    "    by default 10\n",
    "\n",
    "  - `cutoff`:\n",
    "\n",
    "    Expects a tuple of three values where the first two are strings and\n",
    "    the last one is a float value. First string is a cutoff mode. \n",
    "    Currently available are `'none'` where all reflections are used,\n",
    "    `'sin(theta)/lambda'` where the cutoff is set according to a user\n",
    "    given resolution, 'fraction(f0jval)' where the resolution cutoff is\n",
    "    set to include a certain fraction of the mean absolute *valence* \n",
    "    atomic form factors. `'I/esd(I)'` can be used for excluding values\n",
    "    based on the value over estimated standard deviation\n",
    "    The second string can be either be 'above' or 'below' and \n",
    "    denominates in which direction values will be excluded.\n",
    "    The final value is the actual cutoff value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0184ad-1e50-4bc6-a87f-b35bff625494",
   "metadata": {},
   "outputs": [],
   "source": [
    "refinement_dict_caf2 = {\n",
    "    'f0j_source': 'qe',\n",
    "    'reload_step': 1,\n",
    "    'core': 'constant'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed8ed5-05d0-4b7e-bc7f-7c19b8d85b16",
   "metadata": {},
   "source": [
    "The function in the next cell creates a list of parameters and a recipee of how to reconstruct the atomic parameters from these parameters (which might be non-trivial if we have contraints.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be58e9c-faac-4e33-9103-4464ebb75a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "construction_instructions_caf2, parameters_caf2 = create_construction_instructions(\n",
    "    atom_table=atom_table_caf2,\n",
    "    constraint_dict=constraints_caf2,\n",
    "    refinement_dict=refinement_dict_caf2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68f1143-cb56-4011-8949-6e4b35db5dbe",
   "metadata": {},
   "source": [
    "### Setting the options for the calculation\n",
    "This dictionary is specific for each choice of `f0j_source` in the `refinement_dict`. It consists of some XHARPy specific options and then program specific options. Using your knowledge from the Quantum Espresso tutorial you might guess that the program specific options will be used to write an input file for `pw.x`. With some info added by XHARPy (for reference see [QE's pw.x input description](https://www.quantum-espresso.org/Doc/INPUT_PW.html)). More information about the individual computation dicts can be found in the [online documentation of XHARPy](https://xharpy.readthedocs.io/en/latest/library/library_f0j.html).\n",
    "\n",
    "Unfortunately, XHARPy with QE can only work with lattices expressed as primitive (even if they are not, as in this case), as the coordinate transformation needed for centrings is not implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df2037b-8028-4134-8050-07bc4a0d6e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "computation_dict_caf2 = {\n",
    "    'symm_equiv': 'once', # XHARPy specific: f0j only evaluated once for every atom in asymmetric unit\n",
    "    'mpicores': 2, # Sets the number of mpi cores. Make sure that n(MPI) * n(OMP) < N(Threads CPU)\n",
    "\n",
    "    'control': {\n",
    "        'prefix': 'CaF2',\n",
    "        'pseudo_dir': './CaF2/pseudo/',\n",
    "    },\n",
    "    'system': {\n",
    "        'ibrav': 1,\n",
    "        'a': float(cell_caf2[0]),\n",
    "        'ecutwfc': 100,\n",
    "        'ecutrho': 400,\n",
    "    },\n",
    "    'paw_files': {\n",
    "        'Ca': 'Ca.paw.upf',\n",
    "        'F': 'F.paw.upf',\n",
    "    },\n",
    "    'k_points':{\n",
    "        'mode': 'automatic',\n",
    "        'input': '1 1 1 0 0 0'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee522a1a-5109-47bb-9c1c-e72a7184568e",
   "metadata": {},
   "source": [
    "## Start the refinement\n",
    "Now that we have assembled all the information and set all the options we can refine with atomic form factors calculated by Quantum Espresso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d674e7d7-35db-42f4-8a6a-9978cb3228ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_caf2, var_cov_mat_caf2, information_caf2 = refine(\n",
    "    cell=cell_caf2, \n",
    "    symm_mats_vecs=symm_mats_vecs_caf2,\n",
    "    hkl=hkl_caf2,\n",
    "    construction_instructions=construction_instructions_caf2,\n",
    "    parameters=parameters_caf2,\n",
    "    wavelength=wavelength_caf2,\n",
    "    refinement_dict=refinement_dict_caf2,\n",
    "    computation_dict=computation_dict_caf2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389c32e6-e436-431e-a645-17efa997eab4",
   "metadata": {},
   "source": [
    "## Writing the results back to disk\n",
    "After we have done out calculation we of course want to write the results back to disk. For this, XHARPy relies a lot on pre-existing files from ShelXL, which it uses to complete its output files.\n",
    "\n",
    "We can now write an fcf(4) file for publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6d64c9-57e2-431e-abfc-e169f141b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_fcf(\n",
    "    fcf_path=output_folder_caf2 / 'xharpy.fcf',\n",
    "    fcf_dataset='xharpy',\n",
    "    fcf_mode=4,\n",
    "    cell=cell_caf2,\n",
    "    hkl=hkl_caf2,\n",
    "    construction_instructions=construction_instructions_caf2,\n",
    "    parameters=parameters_caf2,\n",
    "    wavelength=wavelength_caf2,\n",
    "    refinement_dict=refinement_dict_caf2,\n",
    "    symm_strings=symm_strings_caf2,\n",
    "    information=information_caf2,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cbeab2-de57-4fe7-8cb5-658c95827e61",
   "metadata": {},
   "source": [
    "### Writing an fcf(6) and SHELXL res for the difference electron density\n",
    "Using template files we can also output a SHELXL format res and an fcf(6). We can use this to display the structure and the difference electron density in software like MolecoolQt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283701f-3dc1-41bb-9d2a-ace0b40fc121",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_fcf(\n",
    "    fcf_path=output_folder_caf2 / 'xharpy_6.fcf',\n",
    "    fcf_dataset='xharpy_6',\n",
    "    fcf_mode=6,\n",
    "    cell=cell_caf2,\n",
    "    hkl=hkl_caf2,\n",
    "    construction_instructions=construction_instructions_caf2,\n",
    "    parameters=parameters_caf2,\n",
    "    wavelength=wavelength_caf2,\n",
    "    refinement_dict=refinement_dict_caf2,\n",
    "    symm_strings=symm_strings_caf2,\n",
    "    information=information_caf2,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be29c444-f47f-4be2-983f-003fe43ecd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_res(\n",
    "    out_res_path=output_folder_caf2 / 'xharpy_6.res',\n",
    "    in_res_path=folder_caf2 / 'CaF2.lst',\n",
    "    cell=cell_caf2,\n",
    "    cell_esd=cell_esd_caf2,\n",
    "    construction_instructions=construction_instructions_caf2,\n",
    "    parameters=parameters_caf2,\n",
    "    wavelength=wavelength_caf2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4518ac7-7c4a-4808-9d8e-b2a7e9ca6d67",
   "metadata": {},
   "source": [
    "### Writing a cif file and adding the difference electron density\n",
    "The cif file is also generated using a template (to reduce the amount of finalising needed). The bond and angle table are used to generate updated tables for the new cif files. Because bonds to hydrogen atoms might be omitted in out IAM refinement, we get a warning telling us to check whether the absence of bonds with hydrogen as bonding partners is expected. (Which it is in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec4d23-05a3-4549-be6c-48c55f041928",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_cif(\n",
    "    output_cif_path=output_folder_caf2 / 'xharpy.cif',\n",
    "    cif_dataset='xharpy',\n",
    "    shelx_cif_path=folder_caf2 / 'CaF2.cif',\n",
    "    shelx_dataset=0,\n",
    "    cell=cell_caf2,\n",
    "    cell_esd=cell_esd_caf2,\n",
    "    symm_mats_vecs=symm_mats_vecs_caf2,\n",
    "    hkl=hkl_caf2,\n",
    "    construction_instructions=construction_instructions_caf2,\n",
    "    parameters=parameters_caf2,\n",
    "    var_cov_mat=var_cov_mat_caf2,\n",
    "    refinement_dict=refinement_dict_caf2,\n",
    "    computation_dict=computation_dict_caf2,\n",
    "    information=information_caf2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd560cc-ddfe-4b81-8888-ae9fe1bfd0f1",
   "metadata": {},
   "source": [
    "XHARPy has no way to generate difference electron densities on its own. Instead it relies on cctbx. Unfortunately, that means we need to add the difference electron density entries using the fcf6 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d38599c-1608-4756-af16-00502cc9a1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_density_entries_from_fcf(output_folder_caf2 / 'xharpy.cif', str(output_folder_caf2 / 'xharpy_6.fcf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a91e9d-1953-478f-a65d-128ae894c83b",
   "metadata": {},
   "source": [
    "### Exporting a tsc File from a Refinement result\n",
    "If we want to use the result in other software we can just export a [tsc file](https://arxiv.org/pdf/1911.08847.pdf) for our final refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759140b6-3baa-498d-a5b2-f6cad6da9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xharpy.io import f0j2tsc\n",
    "f0j2tsc(\n",
    "    file_name=output_folder_caf2 / 'xharpy.tsc',\n",
    "    f0j=information_caf2['f0j_anom'],\n",
    "    construction_instructions=construction_instructions_caf2,\n",
    "    symm_mats_vecs=symm_mats_vecs_caf2,\n",
    "    index_vec_h=hkl_caf2[['h', 'k', 'l']].values,\n",
    "    remove_anom=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50cfdd9-9d45-4a4e-8029-9f1114db66ab",
   "metadata": {},
   "source": [
    "## Writing a tsc for a given CIF\n",
    "This code demonstrates two things: The direct generation of a tsc from a given cif and using gpaw_mpi as a backend. The options of the needed `export_dict` can be accessed by the in code documentation of cif2tsc. The main addition is the definition of a resolution limit up until which we generate the f0j. The `computation_dict` is identical to the one we would use for refinement using GPAW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5135e-6e96-4a47-962e-31c770267825",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cif2tsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275d3c9d-51de-49ef-b8c3-f36350963144",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_urea = Path('./urea')\n",
    "output_folder_urea = folder_urea / 'xharpy_output'\n",
    "output_folder_urea.mkdir(exist_ok=True)\n",
    "\n",
    "export_dict_urea = {\n",
    "    'f0j_source': 'gpaw_mpi',\n",
    "    'core': 'constant',\n",
    "    'resolution_limit': 'cif'\n",
    "}\n",
    "\n",
    "computation_dict_urea = {\n",
    "    'symm_equiv': 'once',\n",
    "    'gridinterpolation': 4, \n",
    "    'xc': 'SCAN',\n",
    "    'txt': output_folder_urea / 'gpaw.txt',\n",
    "    'mode': 'fd',\n",
    "    'h': 0.16,\n",
    "    'convergence':{'density': 1e-7},\n",
    "    'kpts': {'size': (1, 1, 1), 'gamma': True},\n",
    "    'symmetry': {'symmorphic': False},\n",
    "    'nbands': -2,\n",
    "    'save_file': output_folder_urea / 'gpaw_result.gpw'\n",
    "}\n",
    "\n",
    "cif2tsc(\n",
    "    tsc_path=output_folder_urea / 'xharpy.tsc',\n",
    "    cif_path=folder_urea / 'iam.cif',\n",
    "    cif_dataset=0,\n",
    "    export_dict=export_dict_urea,\n",
    "    computation_dict=computation_dict_urea\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a08f210-51d7-4c86-82d0-827d35ab341d",
   "metadata": {},
   "source": [
    "# What is different to other HAR implementations here?\n",
    "Just as with the other programs for Hirshfeld atom refinement, such as Tonto and NoSpherA2, XHARPy partitions the densities of atoms. There are three differences to the other approaches. \n",
    " 1. The underlying calculation is periodic using projector augmented waves (PAW) with a plane wave (Quantum Espresso) or real-space grid (GPAW) basis.\n",
    " 2. The valence density (not the pseudo density!) is expanded onto a rectangular grid, partitioned and then Fourier transformed via FFT\n",
    " 3. The spherical frozen core density is evaluated on a non-uniform linear grid (more points at the centre) as spherically symmetry\n",
    "\n",
    "Because the PAW bases are constructed via calculating a free atom, we use these free atoms as libraries for our atomic densities in Hirshfeld partitioning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23248a5-8e38-434c-a982-dd8af71aa86d",
   "metadata": {},
   "source": [
    "# Working outside of Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bdb0c6-9636-4214-abdd-4eb2b7125175",
   "metadata": {},
   "source": [
    "## A quick word about the CLI(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014ba61b-b0bf-4e59-afae-91bc3b7a0127",
   "metadata": {},
   "source": [
    "There is two command line interace scripts available with a very limited subset of the available functionality. At the moment these also only support GPAW. You can access them by typing the following command (with the XHARPy conda environment active).\n",
    "\n",
    "```bash\n",
    "python -m xharpy.cli_refine\n",
    "python -m xharpy.cli_tsc\n",
    "```\n",
    "for doing a refinement or generating a tsc file respectively. You can pass the flag `--help` to get information on how to pass more information in a non-interactive mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95fdd3a-14f9-455b-bf5e-d3efb5462d50",
   "metadata": {},
   "source": [
    "## Exporting a Jupyter notebook as python script\n",
    "You can directly download the code from a notebook as a python script using Jupyter's File menu. This makes things available for a less interactive session (say on a cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0410c56f-d3b6-4462-9e3b-bd2c25c8daa5",
   "metadata": {},
   "source": [
    "# Final remarks\n",
    "Just as in a LCAO refinement, you need to list the size of the used basis, when reporting for publications and presentations, as well as the employed functional.\n",
    " - For Quantum Espresso list the cutoff energies and the employed $k$-point grid.\n",
    " - For GPAW list the grid spacing (`h` in the `computation_dict`) and the employed $k$-point grid.\n",
    " \n",
    "Currently unavailable is the refinement of spin-polarised systems (as in unpaired electrons).\n",
    "\n",
    "The full code and more examples are available at: [https://github.com/Niolon/XHARPy](https://github.com/Niolon/XHARPy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
